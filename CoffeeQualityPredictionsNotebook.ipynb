{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\oviya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\oviya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import needed libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished scraping page 8, now have 17 rows in dataset\n",
      "Finished scraping page 9, now have 37 rows in dataset\n",
      "Finished scraping page 10, now have 55 rows in dataset\n",
      "Finished scraping page 11, now have 72 rows in dataset\n",
      "Finished scraping page 12, now have 89 rows in dataset\n",
      "Finished scraping page 13, now have 108 rows in dataset\n",
      "Finished scraping page 14, now have 128 rows in dataset\n",
      "Finished scraping page 15, now have 148 rows in dataset\n",
      "Finished scraping page 16, now have 166 rows in dataset\n",
      "Finished scraping page 17, now have 186 rows in dataset\n",
      "Finished scraping page 18, now have 206 rows in dataset\n",
      "Finished scraping page 19, now have 224 rows in dataset\n",
      "Finished scraping page 20, now have 244 rows in dataset\n",
      "Finished scraping page 21, now have 261 rows in dataset\n",
      "Finished scraping page 22, now have 278 rows in dataset\n",
      "Finished scraping page 23, now have 295 rows in dataset\n",
      "Finished scraping page 24, now have 308 rows in dataset\n",
      "Finished scraping page 25, now have 324 rows in dataset\n",
      "Finished scraping page 26, now have 343 rows in dataset\n",
      "Finished scraping page 27, now have 357 rows in dataset\n",
      "Finished scraping page 28, now have 369 rows in dataset\n",
      "Finished scraping page 29, now have 377 rows in dataset\n",
      "Finished scraping page 30, now have 388 rows in dataset\n",
      "Finished scraping page 31, now have 402 rows in dataset\n",
      "Finished scraping page 32, now have 416 rows in dataset\n",
      "Finished scraping page 33, now have 435 rows in dataset\n",
      "Finished scraping page 34, now have 452 rows in dataset\n",
      "Finished scraping page 35, now have 471 rows in dataset\n",
      "Finished scraping page 36, now have 485 rows in dataset\n",
      "Finished scraping page 37, now have 503 rows in dataset\n",
      "Finished scraping page 38, now have 523 rows in dataset\n",
      "Finished scraping page 39, now have 541 rows in dataset\n",
      "Finished scraping page 40, now have 560 rows in dataset\n",
      "Finished scraping page 41, now have 576 rows in dataset\n",
      "Finished scraping page 42, now have 593 rows in dataset\n",
      "Finished scraping page 43, now have 613 rows in dataset\n",
      "Finished scraping page 44, now have 632 rows in dataset\n",
      "Finished scraping page 45, now have 651 rows in dataset\n",
      "Finished scraping page 46, now have 668 rows in dataset\n",
      "Finished scraping page 47, now have 688 rows in dataset\n",
      "Finished scraping page 48, now have 703 rows in dataset\n",
      "Finished scraping page 49, now have 721 rows in dataset\n",
      "Finished scraping page 50, now have 740 rows in dataset\n",
      "Finished scraping page 51, now have 759 rows in dataset\n",
      "Finished scraping page 52, now have 778 rows in dataset\n",
      "Finished scraping page 53, now have 795 rows in dataset\n",
      "Finished scraping page 54, now have 811 rows in dataset\n",
      "Finished scraping page 55, now have 830 rows in dataset\n",
      "Finished scraping page 56, now have 848 rows in dataset\n",
      "Finished scraping page 57, now have 868 rows in dataset\n",
      "Finished scraping page 58, now have 887 rows in dataset\n",
      "Finished scraping page 59, now have 905 rows in dataset\n",
      "Finished scraping page 60, now have 924 rows in dataset\n",
      "Finished scraping page 61, now have 939 rows in dataset\n",
      "Finished scraping page 62, now have 957 rows in dataset\n",
      "Finished scraping page 63, now have 974 rows in dataset\n",
      "Finished scraping page 64, now have 991 rows in dataset\n",
      "Finished scraping page 65, now have 1010 rows in dataset\n",
      "Finished scraping page 66, now have 1030 rows in dataset\n",
      "Finished scraping page 67, now have 1047 rows in dataset\n",
      "Finished scraping page 68, now have 1067 rows in dataset\n",
      "Finished scraping page 69, now have 1085 rows in dataset\n",
      "Finished scraping page 70, now have 1104 rows in dataset\n",
      "Finished scraping page 71, now have 1123 rows in dataset\n",
      "Finished scraping page 72, now have 1139 rows in dataset\n",
      "Finished scraping page 73, now have 1157 rows in dataset\n",
      "Finished scraping page 74, now have 1177 rows in dataset\n",
      "Finished scraping page 75, now have 1194 rows in dataset\n",
      "Finished scraping page 76, now have 1211 rows in dataset\n",
      "Finished scraping page 77, now have 1227 rows in dataset\n",
      "Finished scraping page 78, now have 1247 rows in dataset\n",
      "Finished scraping page 79, now have 1264 rows in dataset\n",
      "Finished scraping page 80, now have 1283 rows in dataset\n",
      "Finished scraping page 81, now have 1297 rows in dataset\n",
      "Finished scraping page 82, now have 1315 rows in dataset\n",
      "Finished scraping page 83, now have 1325 rows in dataset\n",
      "Finished scraping page 84, now have 1342 rows in dataset\n",
      "Finished scraping page 85, now have 1361 rows in dataset\n",
      "Finished scraping page 86, now have 1380 rows in dataset\n",
      "Finished scraping page 87, now have 1400 rows in dataset\n",
      "Finished scraping page 88, now have 1418 rows in dataset\n",
      "Finished scraping page 89, now have 1435 rows in dataset\n",
      "Finished scraping page 90, now have 1455 rows in dataset\n",
      "Finished scraping page 91, now have 1473 rows in dataset\n",
      "Finished scraping page 92, now have 1489 rows in dataset\n",
      "Finished scraping page 93, now have 1508 rows in dataset\n",
      "Finished scraping page 94, now have 1522 rows in dataset\n",
      "Finished scraping page 95, now have 1540 rows in dataset\n",
      "Finished scraping page 96, now have 1559 rows in dataset\n",
      "Finished scraping page 97, now have 1578 rows in dataset\n",
      "Finished scraping page 98, now have 1596 rows in dataset\n",
      "Finished scraping page 99, now have 1615 rows in dataset\n",
      "Finished scraping page 100, now have 1630 rows in dataset\n",
      "Finished scraping page 101, now have 1649 rows in dataset\n",
      "Finished scraping page 102, now have 1664 rows in dataset\n",
      "Finished scraping page 103, now have 1683 rows in dataset\n",
      "Finished scraping page 104, now have 1702 rows in dataset\n",
      "Finished scraping page 105, now have 1720 rows in dataset\n",
      "Finished scraping page 106, now have 1733 rows in dataset\n",
      "Finished scraping page 107, now have 1741 rows in dataset\n",
      "Finished scraping page 108, now have 1759 rows in dataset\n",
      "Finished scraping page 109, now have 1768 rows in dataset\n",
      "Finished scraping page 110, now have 1783 rows in dataset\n",
      "Finished scraping page 111, now have 1802 rows in dataset\n",
      "Finished scraping page 112, now have 1820 rows in dataset\n",
      "Finished scraping page 113, now have 1834 rows in dataset\n",
      "Finished scraping page 114, now have 1845 rows in dataset\n",
      "Finished scraping page 115, now have 1864 rows in dataset\n",
      "Finished scraping page 116, now have 1883 rows in dataset\n",
      "Finished scraping page 117, now have 1899 rows in dataset\n",
      "Finished scraping page 118, now have 1916 rows in dataset\n",
      "Finished scraping page 119, now have 1935 rows in dataset\n",
      "Finished scraping page 120, now have 1952 rows in dataset\n",
      "Finished scraping page 121, now have 1971 rows in dataset\n",
      "Finished scraping page 122, now have 1987 rows in dataset\n",
      "Finished scraping page 123, now have 2006 rows in dataset\n",
      "Finished scraping page 124, now have 2025 rows in dataset\n",
      "Finished scraping page 125, now have 2041 rows in dataset\n",
      "Finished scraping page 126, now have 2061 rows in dataset\n",
      "Finished scraping page 127, now have 2080 rows in dataset\n",
      "Finished scraping page 128, now have 2099 rows in dataset\n",
      "Finished scraping page 129, now have 2117 rows in dataset\n",
      "Finished scraping page 130, now have 2136 rows in dataset\n",
      "Finished scraping page 131, now have 2153 rows in dataset\n",
      "Finished scraping page 132, now have 2172 rows in dataset\n",
      "Finished scraping page 133, now have 2189 rows in dataset\n",
      "Finished scraping page 134, now have 2208 rows in dataset\n",
      "Finished scraping page 135, now have 2228 rows in dataset\n",
      "Finished scraping page 136, now have 2243 rows in dataset\n",
      "Finished scraping page 137, now have 2257 rows in dataset\n",
      "Finished scraping page 138, now have 2268 rows in dataset\n",
      "Finished scraping page 139, now have 2285 rows in dataset\n",
      "Finished scraping page 140, now have 2304 rows in dataset\n",
      "Finished scraping page 141, now have 2324 rows in dataset\n",
      "Finished scraping page 142, now have 2344 rows in dataset\n",
      "Finished scraping page 143, now have 2361 rows in dataset\n",
      "Finished scraping page 144, now have 2377 rows in dataset\n",
      "Finished scraping page 145, now have 2393 rows in dataset\n",
      "Finished scraping page 146, now have 2409 rows in dataset\n",
      "Finished scraping page 147, now have 2424 rows in dataset\n",
      "Finished scraping page 148, now have 2444 rows in dataset\n",
      "Finished scraping page 149, now have 2461 rows in dataset\n",
      "Finished scraping page 150, now have 2475 rows in dataset\n",
      "Finished scraping page 151, now have 2493 rows in dataset\n",
      "Finished scraping page 152, now have 2510 rows in dataset\n",
      "Finished scraping page 153, now have 2525 rows in dataset\n",
      "Finished scraping page 154, now have 2543 rows in dataset\n",
      "Finished scraping page 155, now have 2553 rows in dataset\n",
      "Finished scraping page 156, now have 2564 rows in dataset\n",
      "Finished scraping page 157, now have 2579 rows in dataset\n",
      "Finished scraping page 158, now have 2596 rows in dataset\n",
      "Finished scraping page 159, now have 2614 rows in dataset\n",
      "Finished scraping page 160, now have 2631 rows in dataset\n",
      "Finished scraping page 161, now have 2649 rows in dataset\n",
      "Finished scraping page 162, now have 2668 rows in dataset\n",
      "Finished scraping page 163, now have 2686 rows in dataset\n",
      "Finished scraping page 164, now have 2706 rows in dataset\n",
      "Finished scraping page 165, now have 2721 rows in dataset\n",
      "Finished scraping page 166, now have 2740 rows in dataset\n",
      "Finished scraping page 167, now have 2756 rows in dataset\n",
      "Finished scraping page 168, now have 2773 rows in dataset\n",
      "Finished scraping page 169, now have 2788 rows in dataset\n",
      "Finished scraping page 170, now have 2808 rows in dataset\n",
      "Finished scraping page 171, now have 2813 rows in dataset\n",
      "Finished scraping page 172, now have 2828 rows in dataset\n",
      "Finished scraping page 173, now have 2831 rows in dataset\n",
      "Finished scraping page 174, now have 2846 rows in dataset\n",
      "Finished scraping page 175, now have 2866 rows in dataset\n",
      "Finished scraping page 176, now have 2884 rows in dataset\n",
      "Finished scraping page 177, now have 2899 rows in dataset\n",
      "Finished scraping page 178, now have 2915 rows in dataset\n",
      "Finished scraping page 179, now have 2934 rows in dataset\n",
      "Finished scraping page 180, now have 2949 rows in dataset\n",
      "Finished scraping page 181, now have 2967 rows in dataset\n",
      "Finished scraping page 182, now have 2986 rows in dataset\n",
      "Finished scraping page 183, now have 3004 rows in dataset\n",
      "Finished scraping page 184, now have 3015 rows in dataset\n",
      "Finished scraping page 185, now have 3032 rows in dataset\n",
      "Finished scraping page 186, now have 3049 rows in dataset\n",
      "Finished scraping page 187, now have 3068 rows in dataset\n",
      "Finished scraping page 188, now have 3086 rows in dataset\n",
      "Finished scraping page 189, now have 3100 rows in dataset\n",
      "Finished scraping page 190, now have 3100 rows in dataset\n",
      "Finished scraping page 191, now have 3100 rows in dataset\n",
      "Finished scraping page 192, now have 3100 rows in dataset\n",
      "Finished scraping page 193, now have 3100 rows in dataset\n",
      "Finished scraping page 194, now have 3100 rows in dataset\n",
      "Finished scraping page 195, now have 3100 rows in dataset\n",
      "Finished scraping page 196, now have 3100 rows in dataset\n",
      "Finished scraping page 197, now have 3100 rows in dataset\n",
      "Finished scraping page 198, now have 3100 rows in dataset\n",
      "Finished scraping page 199, now have 3100 rows in dataset\n",
      "Finished scraping page 200, now have 3100 rows in dataset\n",
      "Finished scraping page 201, now have 3100 rows in dataset\n",
      "Finished scraping page 202, now have 3100 rows in dataset\n",
      "Finished scraping page 203, now have 3100 rows in dataset\n",
      "Finished scraping page 204, now have 3100 rows in dataset\n",
      "Finished scraping page 205, now have 3100 rows in dataset\n",
      "Finished scraping page 206, now have 3100 rows in dataset\n",
      "Finished scraping page 207, now have 3100 rows in dataset\n",
      "Finished scraping page 208, now have 3100 rows in dataset\n",
      "Finished scraping page 209, now have 3100 rows in dataset\n",
      "Finished scraping page 210, now have 3100 rows in dataset\n",
      "Finished scraping page 211, now have 3100 rows in dataset\n",
      "Finished scraping page 212, now have 3100 rows in dataset\n",
      "Finished scraping page 213, now have 3100 rows in dataset\n",
      "Finished scraping page 214, now have 3100 rows in dataset\n",
      "Finished scraping page 215, now have 3100 rows in dataset\n",
      "Finished scraping page 216, now have 3100 rows in dataset\n",
      "Finished scraping page 217, now have 3100 rows in dataset\n",
      "Finished scraping page 218, now have 3100 rows in dataset\n",
      "Finished scraping page 219, now have 3100 rows in dataset\n",
      "Finished scraping page 220, now have 3100 rows in dataset\n",
      "Finished scraping page 221, now have 3100 rows in dataset\n",
      "Finished scraping page 222, now have 3100 rows in dataset\n",
      "Finished scraping page 223, now have 3100 rows in dataset\n",
      "Finished scraping page 224, now have 3100 rows in dataset\n",
      "Finished scraping page 225, now have 3100 rows in dataset\n",
      "Finished scraping page 226, now have 3100 rows in dataset\n",
      "Finished scraping page 227, now have 3100 rows in dataset\n",
      "Finished scraping page 228, now have 3100 rows in dataset\n",
      "Finished scraping page 229, now have 3100 rows in dataset\n",
      "Finished scraping page 230, now have 3100 rows in dataset\n",
      "Finished scraping page 231, now have 3100 rows in dataset\n",
      "Finished scraping page 236, now have 3100 rows in dataset\n",
      "Finished scraping page 237, now have 3100 rows in dataset\n",
      "Finished scraping page 238, now have 3100 rows in dataset\n",
      "Finished scraping page 239, now have 3100 rows in dataset\n",
      "Finished scraping page 240, now have 3100 rows in dataset\n",
      "Finished scraping page 241, now have 3100 rows in dataset\n",
      "Finished scraping page 242, now have 3100 rows in dataset\n",
      "Finished scraping page 243, now have 3100 rows in dataset\n",
      "Finished scraping page 244, now have 3100 rows in dataset\n",
      "Finished scraping page 245, now have 3100 rows in dataset\n",
      "Finished scraping page 246, now have 3100 rows in dataset\n",
      "Finished scraping page 247, now have 3100 rows in dataset\n",
      "Finished scraping page 248, now have 3100 rows in dataset\n",
      "Finished scraping page 249, now have 3100 rows in dataset\n",
      "Finished scraping page 250, now have 3100 rows in dataset\n",
      "Finished scraping page 251, now have 3100 rows in dataset\n",
      "Finished scraping page 252, now have 3100 rows in dataset\n",
      "Finished scraping page 253, now have 3100 rows in dataset\n",
      "Finished scraping page 254, now have 3100 rows in dataset\n",
      "Finished scraping page 255, now have 3100 rows in dataset\n",
      "Finished scraping page 256, now have 3100 rows in dataset\n",
      "Finished scraping page 257, now have 3100 rows in dataset\n",
      "Finished scraping page 258, now have 3100 rows in dataset\n",
      "Finished scraping page 259, now have 3100 rows in dataset\n",
      "Finished scraping page 260, now have 3100 rows in dataset\n",
      "Finished scraping page 261, now have 3100 rows in dataset\n",
      "Finished scraping page 262, now have 3100 rows in dataset\n",
      "Finished scraping page 263, now have 3100 rows in dataset\n",
      "Finished scraping page 264, now have 3100 rows in dataset\n",
      "Finished scraping page 265, now have 3100 rows in dataset\n",
      "Finished scraping page 266, now have 3100 rows in dataset\n",
      "Finished scraping page 267, now have 3100 rows in dataset\n",
      "Finished scraping page 268, now have 3100 rows in dataset\n",
      "Finished scraping page 269, now have 3100 rows in dataset\n",
      "Finished scraping page 270, now have 3100 rows in dataset\n",
      "Finished scraping page 271, now have 3100 rows in dataset\n",
      "Finished scraping page 272, now have 3100 rows in dataset\n",
      "Finished scraping page 273, now have 3100 rows in dataset\n",
      "Finished scraping page 274, now have 3100 rows in dataset\n",
      "Finished scraping page 275, now have 3100 rows in dataset\n",
      "Finished scraping page 276, now have 3100 rows in dataset\n",
      "Finished scraping page 277, now have 3100 rows in dataset\n",
      "Finished scraping page 278, now have 3100 rows in dataset\n",
      "Finished scraping page 279, now have 3100 rows in dataset\n",
      "Finished scraping page 280, now have 3100 rows in dataset\n",
      "Finished scraping page 281, now have 3100 rows in dataset\n",
      "Finished scraping page 282, now have 3100 rows in dataset\n",
      "Finished scraping page 283, now have 3100 rows in dataset\n",
      "Finished scraping page 284, now have 3100 rows in dataset\n",
      "Finished scraping page 285, now have 3100 rows in dataset\n",
      "Finished scraping page 286, now have 3100 rows in dataset\n",
      "Finished scraping page 287, now have 3100 rows in dataset\n",
      "Finished scraping page 288, now have 3100 rows in dataset\n",
      "Finished scraping page 289, now have 3100 rows in dataset\n",
      "Finished scraping page 290, now have 3100 rows in dataset\n",
      "Finished scraping page 291, now have 3100 rows in dataset\n",
      "Finished scraping page 292, now have 3100 rows in dataset\n",
      "Finished scraping page 293, now have 3100 rows in dataset\n",
      "Finished scraping page 294, now have 3100 rows in dataset\n",
      "Finished scraping page 295, now have 3100 rows in dataset\n",
      "Finished scraping page 296, now have 3100 rows in dataset\n",
      "Finished scraping page 297, now have 3100 rows in dataset\n",
      "Finished scraping page 298, now have 3100 rows in dataset\n",
      "Finished scraping page 299, now have 3100 rows in dataset\n",
      "Finished scraping page 300, now have 3100 rows in dataset\n",
      "Finished scraping page 301, now have 3100 rows in dataset\n",
      "Finished scraping page 302, now have 3100 rows in dataset\n",
      "Finished scraping page 303, now have 3100 rows in dataset\n",
      "Finished scraping page 304, now have 3100 rows in dataset\n",
      "Finished scraping page 305, now have 3100 rows in dataset\n",
      "Finished scraping page 306, now have 3100 rows in dataset\n",
      "Finished scraping page 307, now have 3100 rows in dataset\n",
      "Finished scraping page 308, now have 3100 rows in dataset\n",
      "Finished scraping page 309, now have 3100 rows in dataset\n",
      "Finished scraping page 310, now have 3100 rows in dataset\n",
      "Finished scraping page 311, now have 3100 rows in dataset\n",
      "Finished scraping page 312, now have 3100 rows in dataset\n",
      "Finished scraping page 313, now have 3100 rows in dataset\n",
      "Finished scraping page 314, now have 3100 rows in dataset\n",
      "Finished scraping page 315, now have 3100 rows in dataset\n",
      "Finished scraping page 316, now have 3100 rows in dataset\n",
      "Finished scraping page 317, now have 3100 rows in dataset\n",
      "Finished scraping page 318, now have 3100 rows in dataset\n",
      "Finished scraping page 319, now have 3100 rows in dataset\n",
      "Finished scraping page 320, now have 3100 rows in dataset\n",
      "Finished scraping page 321, now have 3100 rows in dataset\n",
      "Finished scraping page 322, now have 3100 rows in dataset\n",
      "Finished scraping page 323, now have 3100 rows in dataset\n",
      "Finished scraping page 324, now have 3100 rows in dataset\n",
      "Finished scraping page 325, now have 3100 rows in dataset\n",
      "Finished scraping page 326, now have 3100 rows in dataset\n",
      "Finished scraping page 327, now have 3100 rows in dataset\n",
      "Finished scraping page 328, now have 3100 rows in dataset\n",
      "Finished scraping page 329, now have 3100 rows in dataset\n",
      "Finished scraping page 330, now have 3100 rows in dataset\n",
      "Finished scraping page 331, now have 3100 rows in dataset\n",
      "Finished scraping page 333, now have 3100 rows in dataset\n",
      "Finished scraping page 334, now have 3100 rows in dataset\n",
      "Finished scraping page 335, now have 3100 rows in dataset\n",
      "Finished scraping page 336, now have 3100 rows in dataset\n",
      "Finished scraping page 337, now have 3100 rows in dataset\n",
      "Finished scraping page 338, now have 3100 rows in dataset\n",
      "Finished scraping page 339, now have 3100 rows in dataset\n",
      "Finished scraping page 340, now have 3100 rows in dataset\n",
      "Finished scraping page 341, now have 3100 rows in dataset\n",
      "Finished scraping page 342, now have 3100 rows in dataset\n",
      "Finished scraping page 343, now have 3100 rows in dataset\n",
      "Finished scraping page 344, now have 3100 rows in dataset\n",
      "Finished scraping page 345, now have 3100 rows in dataset\n",
      "Finished scraping page 346, now have 3100 rows in dataset\n",
      "Finished scraping page 347, now have 3100 rows in dataset\n",
      "Finished scraping page 348, now have 3100 rows in dataset\n",
      "Finished scraping page 349, now have 3100 rows in dataset\n",
      "Finished scraping page 350, now have 3100 rows in dataset\n",
      "Scraping completed, DataFrame created, and saved to coffee_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "# base url for CoffeeReview website, specifically the reviews\n",
    "base_url = \"https://www.coffeereview.com/reviews/page/{}/\"\n",
    "\n",
    "# list to store scraped data\n",
    "data = []\n",
    "\n",
    "# loop through 350 pages of the reviews\n",
    "for page in range(1, 351):\n",
    "    # format the url for each page, then send a GET request to that url\n",
    "    url = base_url.format(page)\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # error checking\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to access page {page}\")\n",
    "        continue\n",
    "    \n",
    "    # make a BeautifulSoup object that holds all of the parsed HTML\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    # find all coffee review links on the page\n",
    "    coffee_links = [a[\"href\"] for a in soup.select(\".review-title a\")]\n",
    "    \n",
    "    # loop through each review link\n",
    "    for coffee_url in coffee_links:\n",
    "        # send a GET request to the review link and make a BeautifulSoup object that holds all of the parsed HTML\n",
    "        try:\n",
    "            coffee_page = requests.get(coffee_url)\n",
    "        except:\n",
    "            continue\n",
    "        coffee_soup = BeautifulSoup(coffee_page.text, \"html.parser\")\n",
    "        \n",
    "        try:\n",
    "            name = coffee_soup.find(\"h1\", class_=\"review-title\").text.strip()\n",
    "            rating = coffee_soup.find(\"span\", class_=\"review-template-rating\").text.strip()\n",
    "            # extra step needed \n",
    "            origin_tag = coffee_soup.find(\"td\", string=\"Coffee Origin:\")\n",
    "            origin = origin_tag.find_next_sibling(\"td\").text.strip()\n",
    "\n",
    "            roast_level_tag = coffee_soup.find(\"td\", string=\"Roast Level:\")\n",
    "            roast_level = roast_level_tag.find_next_sibling(\"td\").text.strip()\n",
    "\n",
    "            aroma_tag = coffee_soup.find(\"td\", string=\"Aroma:\")\n",
    "            aroma = aroma_tag.find_next_sibling(\"td\").text.strip()\n",
    "            acid_struct_tag = coffee_soup.find(\"td\", string=\"Acidity/Structure:\")\n",
    "            acid_struct = acid_struct_tag.find_next_sibling(\"td\").text.strip()\n",
    "            body_tag = coffee_soup.find(\"td\", string=\"Body:\")\n",
    "            body = body_tag.find_next_sibling(\"td\").text.strip()\n",
    "            flavor_tag = coffee_soup.find(\"td\", string=\"Flavor:\")\n",
    "            flavor = flavor_tag.find_next_sibling(\"td\").text.strip()\n",
    "            aftertaste_tag = coffee_soup.find(\"td\", string=\"Aftertaste:\")\n",
    "            aftertaste = aftertaste_tag.find_next_sibling(\"td\").text.strip()\n",
    "\n",
    "            review_tag = coffee_soup.find(\"h2\", string=\"Bottom Line\")\n",
    "            review_text = review_tag.find_next_sibling(\"p\").text.strip()\n",
    "\n",
    "            # Append to data list\n",
    "            data.append({\n",
    "                \"Name\": name,\n",
    "                \"Rating\": int(rating),\n",
    "                \"Origin\": origin,\n",
    "                \"Roast Level\": roast_level,\n",
    "                \"Aroma\": int(aroma),\n",
    "                \"Acidity/Structure\": int(acid_struct),\n",
    "                \"Body\": int(body),\n",
    "                \"Flavor\": int(flavor),\n",
    "                \"Aftertaste\": int(aftertaste),\n",
    "                \"Review\": review_text\n",
    "            })\n",
    "\n",
    "        except AttributeError:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Finished scraping page {page}, now have {len(data)} rows in dataset\")\n",
    "\n",
    "# convert to DataFrame and save to a csv file\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"coffee_reviews.csv\", index=False)\n",
    "print(\"Scraping completed, DataFrame created, and saved to coffee_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3100 entries, 0 to 3099\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Name               3100 non-null   object\n",
      " 1   Rating             3100 non-null   int64 \n",
      " 2   Origin             3100 non-null   object\n",
      " 3   Roast Level        3100 non-null   object\n",
      " 4   Aroma              3100 non-null   int64 \n",
      " 5   Acidity/Structure  3100 non-null   int64 \n",
      " 6   Body               3100 non-null   int64 \n",
      " 7   Flavor             3100 non-null   int64 \n",
      " 8   Aftertaste         3100 non-null   int64 \n",
      " 9   Review             3100 non-null   object\n",
      "dtypes: int64(6), object(4)\n",
      "memory usage: 242.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Roast Level</th>\n",
       "      <th>Aroma</th>\n",
       "      <th>Acidity/Structure</th>\n",
       "      <th>Body</th>\n",
       "      <th>Flavor</th>\n",
       "      <th>Aftertaste</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El Salvador Finca Plan de Hoyo</td>\n",
       "      <td>93</td>\n",
       "      <td>Apaneca growing region, El Salvador</td>\n",
       "      <td>Light</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>A balanced, high-toned, cocoa-driven washed El...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Finca Retana</td>\n",
       "      <td>93</td>\n",
       "      <td>Antigua Department, Guatemala</td>\n",
       "      <td>Medium-Light</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>A deeply floral, richly chocolaty Guatemala cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Finca San Ramón</td>\n",
       "      <td>92</td>\n",
       "      <td>San Juan Sacatepequez, Sacatepequez Department...</td>\n",
       "      <td>Medium-Light</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>A bright, balanced, juicy Guatemala Geisha Mal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Todos Santos Cuchumatanán Pacamara</td>\n",
       "      <td>92</td>\n",
       "      <td>Todos Santos Cuchumatán, Huehuetenango Departm...</td>\n",
       "      <td>Medium-Light</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>A sweetly nut-toned, gently floral Guatemala P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finca Huixoc Pacamara</td>\n",
       "      <td>91</td>\n",
       "      <td>La Democracia, Huehuetenango Department, Guate...</td>\n",
       "      <td>Medium-Light</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>A friendly, accessible Guatemala Pacamara, cri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Name  Rating  \\\n",
       "0      El Salvador Finca Plan de Hoyo      93   \n",
       "1                        Finca Retana      93   \n",
       "2                     Finca San Ramón      92   \n",
       "3  Todos Santos Cuchumatanán Pacamara      92   \n",
       "4               Finca Huixoc Pacamara      91   \n",
       "\n",
       "                                              Origin   Roast Level  Aroma  \\\n",
       "0                Apaneca growing region, El Salvador         Light      9   \n",
       "1                      Antigua Department, Guatemala  Medium-Light      9   \n",
       "2  San Juan Sacatepequez, Sacatepequez Department...  Medium-Light      8   \n",
       "3  Todos Santos Cuchumatán, Huehuetenango Departm...  Medium-Light      8   \n",
       "4  La Democracia, Huehuetenango Department, Guate...  Medium-Light      8   \n",
       "\n",
       "   Acidity/Structure  Body  Flavor  Aftertaste  \\\n",
       "0                  9     8       9           8   \n",
       "1                  9     8       9           8   \n",
       "2                  9     8       9           8   \n",
       "3                  8     9       9           8   \n",
       "4                  8     8       9           8   \n",
       "\n",
       "                                              Review  \n",
       "0  A balanced, high-toned, cocoa-driven washed El...  \n",
       "1  A deeply floral, richly chocolaty Guatemala cu...  \n",
       "2  A bright, balanced, juicy Guatemala Geisha Mal...  \n",
       "3  A sweetly nut-toned, gently floral Guatemala P...  \n",
       "4  A friendly, accessible Guatemala Pacamara, cri...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting a glimpse into how the DataFrame looks before NLP pre-processing\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP pre-processing for review_text\n",
    "\n",
    "# define set of stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def cleanReviewText(text):\n",
    "    # make all words lowercase\n",
    "    text = text.lower()\n",
    "    # remove punctuation\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "    # remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # remove stopwords\n",
    "    new_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # lemmatization\n",
    "    lemmas = [lemmatizer.lemmatize(token) for token in new_tokens]\n",
    "\n",
    "    return \" \".join(lemmas)\n",
    "\n",
    "df[\"Cleaned_Review\"] = df[\"Review\"].apply(cleanReviewText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking to ensure cleaned review text is correctly formatted\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double checking there are no null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting sum of how many unique values there are for each column\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualiz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
